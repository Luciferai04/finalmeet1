version: '3.8'

services:
 whisper-live:
 build:
 context: ..
 dockerfile: Dockerfile
 container_name: whisper-live-production
 ports:
 - "7860:7860"
 environment:
 - PYTHONUNBUFFERED=1
 - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
 - LOG_LEVEL=${LOG_LEVEL:-INFO}
 - MAX_QUEUE_SIZE=${MAX_QUEUE_SIZE:-100}
 - ENABLE_GPU=${ENABLE_GPU:-true}
 - GRADIO_SERVER_NAME=0.0.0.0
 - GRADIO_SERVER_PORT=7860
 - HF_HOME=/app/.cache/huggingface
 volumes:
 - ../models:/app/models:ro
 - ../logs:/app/logs
 - model_cache:/app/.cache
 - ../config:/app/config:ro
 restart: unless-stopped
 healthcheck:
 test: ["CMD", "curl", "-f", "http://localhost:7860/health"]
 interval: 30s
 timeout: 10s
 retries: 3
 start_period: 60s
 deploy:
 resources:
 limits:
 memory: 8G
 reservations:
 memory: 4G
 devices:
 - driver: nvidia
 count: 1
 capabilities: [gpu]
 logging:
 driver: "json-file"
 options:
 max-size: "100m"
 max-file: "10"

 nginx:
 image: nginx:alpine
 container_name: whisper-live-nginx
 ports:
 - "80:80"
 - "443:443"
 volumes:
 - ./nginx.conf:/etc/nginx/nginx.conf:ro
 - ./ssl:/etc/nginx/ssl:ro
 depends_on:
 - whisper-live
 restart: unless-stopped

volumes:
 model_cache:
 driver: local

networks:
 default:
 name: whisper-live-network
